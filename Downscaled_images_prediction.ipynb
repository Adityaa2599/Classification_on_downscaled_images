{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "neural-networks-deep-learning",
      "graded_item_id": "TSPse",
      "launcher_item_id": "24mxX"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "Deep+Neural+Network+-+Application.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4A1ldEIgH31x"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn-2Vtc5H31v"
      },
      "source": [
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mOOITNaVwu1"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/drive/MyDrive/ColabNotebooks/SOP')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J11NXU93H31v",
        "outputId": "ca0c6b70-d639-4cfe-ec50-1f01db5afcec"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "from dnn_app_utils import *\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "np.random.seed(1)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_Dbjuw3H31x"
      },
      "source": [
        "## 2 - Dataset\n",
        "\n",
        "You will use the same \"Cat vs non-Cat\" dataset as in \"Logistic Regression as a Neural Network\" (Assignment 2). The model you had built had 70% test accuracy on classifying cats vs non-cats images. Hopefully, your new model will perform a better!\n",
        "\n",
        "**Problem Statement**: You are given a dataset (\"data.h5\") containing:\n",
        "    - a training set of m_train images labelled as cat (1) or non-cat (0)\n",
        "    - a test set of m_test images labelled as cat and non-cat\n",
        "    - each image is of shape (num_px, num_px, 3) where 3 is for the 3 channels (RGB).\n",
        "\n",
        "Let's get more familiar with the dataset. Load the data by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U23iTuk9Jbbb"
      },
      "source": [
        "def load_data():\n",
        "    train_dataset = h5py.File('/content/drive/MyDrive/ColabNotebooks/SOP/datasets/train_catvnoncat.h5', \"r\")\n",
        "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
        "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
        "\n",
        "    test_dataset = h5py.File('/content/drive/MyDrive/ColabNotebooks/SOP/datasets/test_catvnoncat.h5', \"r\")\n",
        "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
        "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
        "\n",
        "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
        "    \n",
        "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "    \n",
        "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEe5TtvtKR8p",
        "outputId": "1cf67453-7946-4d6c-fb44-7be565fba03f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOp6aMH6H31x",
        "outputId": "6f304c5a-89a9-4ed6-d469-72cca9c76cb0"
      },
      "source": [
        "train_x_input, train_y, test_x_input, test_y_input, classes = load_data()\n",
        "print(train_x_input.shape)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(209, 64, 64, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFmyftVxUhSl",
        "outputId": "1bee610c-fb10-4088-d7a5-f82b5f1ce0c6"
      },
      "source": [
        "#11 13 19 28 29 34 38 44 45\n",
        "index = [11,13,28,34,38,45]\n",
        "\n",
        "test_x_temp = np.delete(test_x_input,index,0)\n",
        "test_y = np.delete(test_y_input,index,1)\n",
        "print(test_x_temp.shape)\n",
        "print(test_y.shape)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(44, 64, 64, 3)\n",
            "(1, 44)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHhE4ldnYQUG"
      },
      "source": [
        "**Assign the downscaled value to the paramater 'size' according to which you want the image to be downscaled.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWDB205Co0MG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "292cd565-f856-412d-e3e6-6da0da8dfb42"
      },
      "source": [
        "import cv2\n",
        "size = 50\n",
        "train_x_orig = np.empty((train_x_input.shape[0],size,size,3),dtype =int)\n",
        "for i in range(train_x_input.shape[0]):\n",
        "  res = train_x_input[i]\n",
        "  train_x_orig[i] = cv2.resize(res, dsize=(size,size), interpolation=cv2.INTER_CUBIC)\n",
        "print(train_x_orig.shape)\n",
        "\n",
        "test_x_orig = np.empty((test_x_temp.shape[0],size,size,3),dtype = int)\n",
        "for j in range(test_x_temp.shape[0]):\n",
        "  res_test = test_x_temp[j]\n",
        "  test_x_orig[j] = cv2.resize(res_test, dsize=(size,size), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "print(test_x_orig.shape)\n",
        "\"\"\"train_x_orig = train_x_input\n",
        "test_x_orig = test_x_temp\"\"\""
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(209, 50, 50, 3)\n",
            "(44, 50, 50, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'train_x_orig = train_x_input\\ntest_x_orig = test_x_temp'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "peKs0PkCH31x",
        "outputId": "f5d4b84c-1807-4ff3-dbfb-6e587a80e979"
      },
      "source": [
        "# Example of a picture\n",
        "plt.imshow(train_x_orig[26])\n",
        "#print (\"y = \" + str(train_y[0,index]) + \". It's a \" + classes[train_y[0,index]].decode(\"utf-8\") +  \" picture.\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3f609b1b50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twFqJFYzH31x",
        "outputId": "92dbccef-25cd-4780-871d-6b1b4c176555"
      },
      "source": [
        "# Explore your dataset \n",
        "m_train = train_x_orig.shape[0]\n",
        "num_px = train_x_orig.shape[1]\n",
        "m_test = test_x_orig.shape[0]\n",
        "\n",
        "print (\"Number of training examples: \" + str(m_train))\n",
        "print (\"Number of testing examples: \" + str(m_test))\n",
        "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
        "print (\"train_x_orig shape: \" + str(train_x_orig.shape))\n",
        "print (\"train_y shape: \" + str(train_y.shape))\n",
        "print (\"test_x_orig shape: \" + str(test_x_orig.shape))\n",
        "print (\"test_y shape: \" + str(test_y.shape))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 209\n",
            "Number of testing examples: 44\n",
            "Each image is of size: (50, 50, 3)\n",
            "train_x_orig shape: (209, 50, 50, 3)\n",
            "train_y shape: (1, 209)\n",
            "test_x_orig shape: (44, 50, 50, 3)\n",
            "test_y shape: (1, 44)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt5nmxEZH31x"
      },
      "source": [
        "As usual, you reshape and standardize the images before feeding them to the network. The code is given in the cell below.\n",
        "\n",
        "<img src=\"images/imvectorkiank.png\" style=\"width:450px;height:300px;\">\n",
        "\n",
        "<caption><center> <u>Figure 1</u>: Image to vector conversion. <br> </center></caption>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxDc_lfTH31x",
        "outputId": "03ef92a4-3d1d-4ddf-cf1f-ec0e724de7c7"
      },
      "source": [
        "# Reshape the training and test examples \n",
        "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\n",
        "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
        "\n",
        "# Standardize data to have feature values between 0 and 1.\n",
        "train_x = train_x_flatten/255.\n",
        "test_x = test_x_flatten/255.\n",
        "\n",
        "print (\"train_x's shape: \" + str(train_x.shape))\n",
        "print (\"test_x's shape: \" + str(test_x.shape))\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_x's shape: (7500, 209)\n",
            "test_x's shape: (7500, 44)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LWv46IvH31x"
      },
      "source": [
        "$12,288$ equals $64 \\times 64 \\times 3$ which is the size of one reshaped image vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4A1ldEIgH31x"
      },
      "source": [
        "## 3 - Architecture of your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j5GeobRMWzI"
      },
      "source": [
        "\n",
        "def sigmoid(Z):\n",
        "    \"\"\"\n",
        "    Implements the sigmoid activation in numpy\n",
        "    \n",
        "    Arguments:\n",
        "    Z -- numpy array of any shape\n",
        "    \n",
        "    Returns:\n",
        "    A -- output of sigmoid(z), same shape as Z\n",
        "    cache -- returns Z as well, useful during backpropagation\n",
        "    \"\"\"\n",
        "    \n",
        "    A = 1/(1+np.exp(-Z))\n",
        "    cache = Z\n",
        "    \n",
        "    return A, cache\n",
        "\n",
        "def relu(Z):\n",
        "    \"\"\"\n",
        "    Implement the RELU function.\n",
        "\n",
        "    Arguments:\n",
        "    Z -- Output of the linear layer, of any shape\n",
        "\n",
        "    Returns:\n",
        "    A -- Post-activation parameter, of the same shape as Z\n",
        "    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently\n",
        "    \"\"\"\n",
        "    \n",
        "    A = np.maximum(0,Z)\n",
        "    \n",
        "    assert(A.shape == Z.shape)\n",
        "    \n",
        "    cache = Z \n",
        "    return A, cache\n",
        "\n",
        "\n",
        "def relu_backward(dA, cache):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation for a single RELU unit.\n",
        "\n",
        "    Arguments:\n",
        "    dA -- post-activation gradient, of any shape\n",
        "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
        "\n",
        "    Returns:\n",
        "    dZ -- Gradient of the cost with respect to Z\n",
        "    \"\"\"\n",
        "    \n",
        "    Z = cache\n",
        "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
        "    \n",
        "    # When z <= 0, you should set dz to 0 as well. \n",
        "    dZ[Z <= 0] = 0\n",
        "    \n",
        "    assert (dZ.shape == Z.shape)\n",
        "    \n",
        "    return dZ\n",
        "\n",
        "def sigmoid_backward(dA, cache):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation for a single SIGMOID unit.\n",
        "\n",
        "    Arguments:\n",
        "    dA -- post-activation gradient, of any shape\n",
        "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
        "\n",
        "    Returns:\n",
        "    dZ -- Gradient of the cost with respect to Z\n",
        "    \"\"\"\n",
        "    \n",
        "    Z = cache\n",
        "    \n",
        "    s = 1/(1+np.exp(-Z))\n",
        "    dZ = dA * s * (1-s)\n",
        "    \n",
        "    assert (dZ.shape == Z.shape)\n",
        "    \n",
        "    return dZ\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mLdtD9cK31f"
      },
      "source": [
        "def initialize_parameters_deep(layer_dims):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
        "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
        "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
        "    \"\"\"\n",
        "    \n",
        "    np.random.seed(1)\n",
        "    parameters = {}\n",
        "    L = len(layer_dims)            # number of layers in the network\n",
        "\n",
        "    for l in range(1, L):\n",
        "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) / np.sqrt(layer_dims[l-1]) #*0.01\n",
        "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
        "        \n",
        "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
        "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
        "\n",
        "        \n",
        "    return parameters"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDaGjOZ-L9bD"
      },
      "source": [
        "def linear_forward(A, W, b):\n",
        "    \"\"\"\n",
        "    Implement the linear part of a layer's forward propagation.\n",
        "\n",
        "    Arguments:\n",
        "    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
        "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
        "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
        "\n",
        "    Returns:\n",
        "    Z -- the input of the activation function, also called pre-activation parameter \n",
        "    cache -- a python dictionary containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
        "    \"\"\"\n",
        "    \n",
        "    Z = W.dot(A) + b\n",
        "    \n",
        "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
        "    cache = (A, W, b)\n",
        "    \n",
        "    return Z, cache"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_zX-urhLwL6"
      },
      "source": [
        "def linear_activation_forward(A_prev, W, b, activation):\n",
        "    \"\"\"\n",
        "    Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
        "\n",
        "    Arguments:\n",
        "    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
        "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
        "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
        "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
        "\n",
        "    Returns:\n",
        "    A -- the output of the activation function, also called the post-activation value \n",
        "    cache -- a python dictionary containing \"linear_cache\" and \"activation_cache\";\n",
        "             stored for computing the backward pass efficiently\n",
        "    \"\"\"\n",
        "    \n",
        "    if activation == \"sigmoid\":\n",
        "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
        "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "        A, activation_cache = sigmoid(Z)\n",
        "    \n",
        "    elif activation == \"relu\":\n",
        "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
        "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "        A, activation_cache = relu(Z)\n",
        "    \n",
        "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
        "    cache = (linear_cache, activation_cache)\n",
        "\n",
        "    return A, cache"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbaBzmtCLDa9"
      },
      "source": [
        "def L_model_forward(X, parameters):\n",
        "    \"\"\"\n",
        "    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n",
        "    \n",
        "    Arguments:\n",
        "    X -- data, numpy array of shape (input size, number of examples)\n",
        "    parameters -- output of initialize_parameters_deep()\n",
        "    \n",
        "    Returns:\n",
        "    AL -- last post-activation value\n",
        "    caches -- list of caches containing:\n",
        "                every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)\n",
        "                the cache of linear_sigmoid_forward() (there is one, indexed L-1)\n",
        "    \"\"\"\n",
        "\n",
        "    caches = []\n",
        "    A = X\n",
        "    L = len(parameters) // 2                  # number of layers in the neural network\n",
        "    \n",
        "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
        "    for l in range(1, L):\n",
        "        A_prev = A \n",
        "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation = \"relu\")\n",
        "        caches.append(cache)\n",
        "    \n",
        "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
        "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = \"sigmoid\")\n",
        "    caches.append(cache)\n",
        "    \n",
        "    assert(AL.shape == (1,X.shape[1]))\n",
        "            \n",
        "    return AL, caches"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG7N1PtbLG_R"
      },
      "source": [
        "def compute_cost(AL, Y):\n",
        "    \"\"\"\n",
        "    Implement the cost function defined by equation (7).\n",
        "\n",
        "    Arguments:\n",
        "    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n",
        "    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n",
        "\n",
        "    Returns:\n",
        "    cost -- cross-entropy cost\n",
        "    \"\"\"\n",
        "    \n",
        "    m = Y.shape[1]\n",
        "\n",
        "    # Compute loss from aL and y.\n",
        "    cost = (1./m) * (-np.dot(Y,np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T))\n",
        "    \n",
        "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
        "    assert(cost.shape == ())\n",
        "    \n",
        "    return cost"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2DHwU87MJ3C"
      },
      "source": [
        "\n",
        "def linear_backward(dZ, cache):\n",
        "    \"\"\"\n",
        "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
        "\n",
        "    Arguments:\n",
        "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
        "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
        "\n",
        "    Returns:\n",
        "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
        "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
        "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
        "    \"\"\"\n",
        "    A_prev, W, b = cache\n",
        "    m = A_prev.shape[1]\n",
        "\n",
        "    dW = 1./m * np.dot(dZ,A_prev.T)\n",
        "    db = 1./m * np.sum(dZ, axis = 1, keepdims = True)\n",
        "    dA_prev = np.dot(W.T,dZ)\n",
        "    \n",
        "    assert (dA_prev.shape == A_prev.shape)\n",
        "    assert (dW.shape == W.shape)\n",
        "    assert (db.shape == b.shape)\n",
        "    \n",
        "    return dA_prev, dW, db\n",
        "\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2O7FmcHMMvY"
      },
      "source": [
        "def linear_activation_backward(dA, cache, activation):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
        "    \n",
        "    Arguments:\n",
        "    dA -- post-activation gradient for current layer l \n",
        "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
        "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
        "    \n",
        "    Returns:\n",
        "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
        "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
        "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
        "    \"\"\"\n",
        "    linear_cache, activation_cache = cache\n",
        "    \n",
        "    if activation == \"relu\":\n",
        "        dZ = relu_backward(dA, activation_cache)\n",
        "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
        "        \n",
        "    elif activation == \"sigmoid\":\n",
        "        dZ = sigmoid_backward(dA, activation_cache)\n",
        "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
        "    \n",
        "    return dA_prev, dW, db"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP_-JUCELMAS"
      },
      "source": [
        "def L_model_backward(AL, Y, caches):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n",
        "    \n",
        "    Arguments:\n",
        "    AL -- probability vector, output of the forward propagation (L_model_forward())\n",
        "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
        "    caches -- list of caches containing:\n",
        "                every cache of linear_activation_forward() with \"relu\" (there are (L-1) or them, indexes from 0 to L-2)\n",
        "                the cache of linear_activation_forward() with \"sigmoid\" (there is one, index L-1)\n",
        "    \n",
        "    Returns:\n",
        "    grads -- A dictionary with the gradients\n",
        "             grads[\"dA\" + str(l)] = ... \n",
        "             grads[\"dW\" + str(l)] = ...\n",
        "             grads[\"db\" + str(l)] = ... \n",
        "    \"\"\"\n",
        "    grads = {}\n",
        "    L = len(caches) # the number of layers\n",
        "    m = AL.shape[1]\n",
        "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
        "    \n",
        "    # Initializing the backpropagation\n",
        "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
        "    \n",
        "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"AL, Y, caches\". Outputs: \"grads[\"dAL\"], grads[\"dWL\"], grads[\"dbL\"]\n",
        "    current_cache = caches[L-1]\n",
        "    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"sigmoid\")\n",
        "    \n",
        "    for l in reversed(range(L-1)):\n",
        "        # lth layer: (RELU -> LINEAR) gradients.\n",
        "        current_cache = caches[l]\n",
        "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 2)], current_cache, activation = \"relu\")\n",
        "        grads[\"dA\" + str(l + 1)] = dA_prev_temp\n",
        "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
        "        grads[\"db\" + str(l + 1)] = db_temp\n",
        "\n",
        "    return grads"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_dnWqYgLRJ3"
      },
      "source": [
        "def update_parameters(parameters, grads, learning_rate):\n",
        "    \"\"\"\n",
        "    Update parameters using gradient descent\n",
        "    \n",
        "    Arguments:\n",
        "    parameters -- python dictionary containing your parameters \n",
        "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your updated parameters \n",
        "                  parameters[\"W\" + str(l)] = ... \n",
        "                  parameters[\"b\" + str(l)] = ...\n",
        "    \"\"\"\n",
        "    \n",
        "    L = len(parameters) // 2 # number of layers in the neural network\n",
        "\n",
        "    # Update rule for each parameter. Use a for loop.\n",
        "    for l in range(L):\n",
        "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
        "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
        "        \n",
        "    return parameters"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGCyEBLqH31x"
      },
      "source": [
        "## 5 - L-layer Neural Network\n",
        "\n",
        "**Question**: Use the helper functions you have implemented previously to build an $L$-layer neural network with the following structure: *[LINEAR -> RELU]$\\times$(L-1) -> LINEAR -> SIGMOID*. The functions you may need and their inputs are:\n",
        "```python\n",
        "def initialize_parameters_deep(layers_dims):\n",
        "    ...\n",
        "    return parameters \n",
        "def L_model_forward(X, parameters):\n",
        "    ...\n",
        "    return AL, caches\n",
        "def compute_cost(AL, Y):\n",
        "    ...\n",
        "    return cost\n",
        "def L_model_backward(AL, Y, caches):\n",
        "    ...\n",
        "    return grads\n",
        "def update_parameters(parameters, grads, learning_rate):\n",
        "    ...\n",
        "    return parameters\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs66lUqSTrbP"
      },
      "source": [
        "def initialize_parameters_deep(layer_dims):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
        "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
        "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
        "    \"\"\"\n",
        "    \n",
        "    np.random.seed(1)\n",
        "    parameters = {}\n",
        "    L = len(layer_dims)            # number of layers in the network\n",
        "\n",
        "    for l in range(1, L):\n",
        "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) / np.sqrt(layer_dims[l-1]) #*0.01\n",
        "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
        "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
        "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfZAJT1CH31x"
      },
      "source": [
        "def L_model_backward(AL, Y, caches):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n",
        "    \n",
        "    Arguments:\n",
        "    AL -- probability vector, output of the forward propagation (L_model_forward())\n",
        "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
        "    caches -- list of caches containing:\n",
        "                every cache of linear_activation_forward() with \"relu\" (there are (L-1) or them, indexes from 0 to L-2)\n",
        "                the cache of linear_activation_forward() with \"sigmoid\" (there is one, index L-1)\n",
        "    \n",
        "    Returns:\n",
        "    grads -- A dictionary with the gradients\n",
        "             grads[\"dA\" + str(l)] = ... \n",
        "             grads[\"dW\" + str(l)] = ...\n",
        "             grads[\"db\" + str(l)] = ... \n",
        "    \"\"\"\n",
        "    grads = {}\n",
        "    L = len(caches) # the number of layers\n",
        "    m = AL.shape[1]\n",
        "    #Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
        "    \n",
        "    # Initializing the backpropagation\n",
        "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
        "    \n",
        "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"AL, Y, caches\". Outputs: \"grads[\"dAL\"], grads[\"dWL\"], grads[\"dbL\"]\n",
        "    current_cache = caches[L-1]\n",
        "    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"sigmoid\")\n",
        "    \n",
        "    for l in reversed(range(L-1)):\n",
        "        # lth layer: (RELU -> LINEAR) gradients.\n",
        "        current_cache = caches[l]\n",
        "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 2)], current_cache, activation = \"relu\")\n",
        "        grads[\"dA\" + str(l + 1)] = dA_prev_temp\n",
        "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
        "        grads[\"db\" + str(l + 1)] = db_temp\n",
        "\n",
        "    return grads"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nxy2JWCAM_ry"
      },
      "source": [
        "def predict(X, y, parameters):\n",
        "    \"\"\"\n",
        "    This function is used to predict the results of a  L-layer neural network.\n",
        "    \n",
        "    Arguments:\n",
        "    X -- data set of examples you would like to label\n",
        "    parameters -- parameters of the trained model\n",
        "    \n",
        "    Returns:\n",
        "    p -- predictions for the given dataset X\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[1]\n",
        "    n = len(parameters) // 2 # number of layers in the neural network\n",
        "    p = np.zeros((1, m),dtype=int)\n",
        "    \n",
        "    # Forward propagation\n",
        "    probas, caches = L_model_forward(X, parameters)\n",
        "\n",
        "\n",
        "    # convert probas to 0/1 predictions\n",
        "    for i in range(0, probas.shape[1]):\n",
        "        if probas[0,i] > 0.5:\n",
        "            p[0,i] = 1\n",
        "        else:\n",
        "            p[0,i] = 0\n",
        "\n",
        "    #print results\n",
        "    #print (\"predictions: \" + str(p))\n",
        "    #print (\"true labels: \" + str(y))\n",
        "    print(\"Accuracy: %s\" % str(np.sum(p == y)/float(m)))\n",
        "        \n",
        "    return p\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gmnbDWGNCc4"
      },
      "source": [
        "\n",
        "def print_mislabeled_images(classes, X, y, p):\n",
        "    \"\"\"\n",
        "    Plots images where predictions and truth were different.\n",
        "    X -- dataset\n",
        "    y -- true labels\n",
        "    p -- predictions\n",
        "    \"\"\"\n",
        "    a = p + y\n",
        "    mislabeled_indices = np.asarray(np.where(a == 1))\n",
        "    print(mislabeled_indices)\n",
        "    plt.rcParams['figure.figsize'] = (40.0, 40.0) # set default size of plots\n",
        "    num_images = len(mislabeled_indices[0])\n",
        "    for i in range(num_images):\n",
        "        index = mislabeled_indices[1][i]\n",
        "        print(index)\n",
        "        plt.subplot(2, num_images, i + 1)\n",
        "        plt.imshow(X[:,index].reshape(64,64,3), interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "        plt.title(\"Prediction: \" + classes[int(p[0,index])].decode(\"utf-8\") + \" \\n Class: \" + classes[y[0,index]].decode(\"utf-8\"))\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A8fFw0QH31x"
      },
      "source": [
        "### CONSTANTS ###\n",
        "layers_dims = [train_x.shape[0], 20, 7, 5, 1] #  4-layer model"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUIo5rn0H31x"
      },
      "source": [
        "# GRADED FUNCTION: L_layer_model\n",
        "\n",
        "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations=1200, print_cost=False):#lr was 0.009\n",
        "\n",
        "    \"\"\"\n",
        "    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
        "    \n",
        "    Arguments:\n",
        "    X -- data, numpy array of shape (num_px * num_px * 3, number of examples)\n",
        "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
        "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
        "    learning_rate -- learning rate of the gradient descent update rule\n",
        "    num_iterations -- number of iterations of the optimization loop\n",
        "    print_cost -- if True, it prints the cost every 100 steps\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
        "    \"\"\"\n",
        "\n",
        "    np.random.seed(1)\n",
        "    costs = []                         # keep track of cost\n",
        "    \n",
        "    # Parameters initialization. (≈ 1 line of code)\n",
        "    ### START CODE HERE ###\n",
        "    parameters = initialize_parameters_deep(layers_dims)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Loop (gradient descent)\n",
        "    for i in range(0, num_iterations):\n",
        "\n",
        "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
        "        ### START CODE HERE ### (≈ 1 line of code)\n",
        "        AL, caches =  L_model_forward(X, parameters)\n",
        "        ### END CODE HERE ###\n",
        "        \n",
        "        # Compute cost.\n",
        "        ### START CODE HERE ### (≈ 1 line of code)\n",
        "        cost = compute_cost(AL, Y)\n",
        "        ### END CODE HERE ###\n",
        "    \n",
        "        # Backward propagation.\n",
        "        ### START CODE HERE ### (≈ 1 line of code)\n",
        "        grads = L_model_backward(AL, Y, caches)\n",
        "        ### END CODE HERE ###\n",
        " \n",
        "        # Update parameters.\n",
        "        ### START CODE HERE ### (≈ 1 line of code)\n",
        "        parameters = update_parameters(parameters, grads, learning_rate)\n",
        "        ### END CODE HERE ###\n",
        "                \n",
        "        # Print the cost every 100 training example\n",
        "        if print_cost and i % 100 == 0:\n",
        "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
        "        if print_cost and i % 100 == 0:\n",
        "            costs.append(cost)\n",
        "            \n",
        "    # plot the cost\n",
        "    plt.plot(np.squeeze(costs))\n",
        "    plt.ylabel('cost')\n",
        "    plt.xlabel('iterations (per hundreds)')\n",
        "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "    plt.show()\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuEIn9MdH31x"
      },
      "source": [
        "You will now train the model as a 4-layer neural network. \n",
        "\n",
        "Run the cell below to train your model. The cost should decrease on every iteration. It may take up to 5 minutes to run 2500 iterations. Check if the \"Cost after iteration 0\" matches the expected output below, if not click on the square (⬛) on the upper bar of the notebook to stop the cell and try to find your error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "0-hBw9K6H31x",
        "outputId": "e30fc1db-517c-452e-d309-2eaedcf922d8"
      },
      "source": [
        "parameters = L_layer_model(train_x, train_y, layers_dims, num_iterations=1500, print_cost = True)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration 0: 0.692268\n",
            "Cost after iteration 100: 0.650392\n",
            "Cost after iteration 200: 0.639900\n",
            "Cost after iteration 300: 0.629555\n",
            "Cost after iteration 400: 0.610983\n",
            "Cost after iteration 500: 0.521803\n",
            "Cost after iteration 600: 0.465772\n",
            "Cost after iteration 700: 0.404765\n",
            "Cost after iteration 800: 0.354600\n",
            "Cost after iteration 900: 0.311205\n",
            "Cost after iteration 1000: 0.213704\n",
            "Cost after iteration 1100: 0.128198\n",
            "Cost after iteration 1200: 0.101908\n",
            "Cost after iteration 1300: 0.060699\n",
            "Cost after iteration 1400: 0.042704\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDAueuq4H31y"
      },
      "source": [
        "**Expected Output**:\n",
        "<table> \n",
        "    <tr>\n",
        "        <td> **Cost after iteration 0**</td>\n",
        "        <td> 0.771749 </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td> **Cost after iteration 100**</td>\n",
        "        <td> 0.672053 </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td> **...**</td>\n",
        "        <td> ... </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td> **Cost after iteration 2400**</td>\n",
        "        <td> 0.092878 </td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpL87IQLH31y",
        "outputId": "116c735a-6649-4daf-9c65-413f925288cd"
      },
      "source": [
        "pred_train = predict(train_x, train_y, parameters)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jp3Q23NxH31y",
        "outputId": "c517684a-7a11-44ab-b27e-1968098d08dd"
      },
      "source": [
        "pred_test = predict(test_x, test_y, parameters)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8409090909090909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZTAJcNxH31y"
      },
      "source": [
        "##  6) Results Analysis\n",
        "\n",
        "First, let's take a look at some images the L-layer model labeled incorrectly. This will show a few mislabeled images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3WPFl8w1H31y",
        "outputId": "fc83fb18-1139-44fa-a747-f86b440fd85b"
      },
      "source": [
        "print_mislabeled_images(classes, test_x, test_y, pred_test)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 5  6 16 17 26 39 40]]\n",
            "5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-76d78ca5a144>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_mislabeled_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-70-46fad0411771>\u001b[0m in \u001b[0;36mprint_mislabeled_images\u001b[0;34m(classes, X, y, p)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \\n Class: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 7500 into shape (64,64,3)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2880x2880 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHB39pyBH31y"
      },
      "source": [
        "**A few types of images the model tends to do poorly on include:** \n",
        "- Cat body in an unusual position\n",
        "- Cat appears against a background of a similar color\n",
        "- Unusual cat color and species\n",
        "- Camera Angle\n",
        "- Brightness of the picture\n",
        "- Scale variation (cat is very large or small in image) "
      ]
    }
  ]
}
